---
title: "EDUC 152. Intro to quantitative research in education: Regression analysis"
subtitle: "Bivariate regression"
author: 
date: 
urlcolor: blue
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true # toc_float option to float the table of contents to the left of the main document content. floating table of contents will always be visible even when the document is scrolled
      #collapsed: false # collapsed (defaults to TRUE) controls whether the TOC appears with only the top-level (e.g., H2) headers. If collapsed initially, the TOC is automatically expanded inline when necessary
      #smooth_scroll: true # smooth_scroll (defaults to TRUE) controls whether page scrolls are animated when TOC items are navigated to via mouse clicks
    number_sections: true
    fig_caption: true # ? this option doesn't seem to be working for figure inserted below outside of r code chunk    
    highlight: tango # Supported styles include "default", "tango", "pygments", "kate", "monochrome", "espresso", "zenburn", and "haddock" (specify null to prevent syntax    
    theme: default # theme specifies the Bootstrap theme to use for the page. Valid themes include default, cerulean, journal, flatly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, and yeti.
    df_print: tibble #options: default, tibble, paged
bibliography: ../../assets/bib/educ152_bib.bib
csl: ../../assets/bib/apa.csl
---


<!-- Code to enable scroll right for printing of data frames -->
<style>
pre code, pre, code {
  white-space: pre !important;
  overflow-x: auto !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
</style>


```{r, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", highlight = TRUE, warning = FALSE, message = FALSE)
  #comment = "#>" makes it so results from a code chunk start with "#>"; default is "##"
options(scipen=999)
options(tibble.width = Inf, width = 10000) # Code necessary to enable scroll right for printing of data frames
```

# Introduction

"Bivariate regression" refers to regression models with two variables, a $Y$ variable ("dependent variable" or "outcome") and a single $X$ variable ("independent variable")

<br>

"Multivariate regression" refers to regression models with a $Y$ variable and two or more $X$ variables

<br>

This lecture -- which we will teach over several weeks -- teaches the fundamental concepts of bivariate regression. All of these concepts will be the same when we move on to multivariate regression in the subsequent lecture



## Libraries, data, functions


<details><summary><b>CLICK HERE FOR OZAN'S NOTES TO SELF ON WHICH YEAR OF IPEDS TUITION PRICE DATA TO MERGE TO WHICH YEAR OF SCORECARD DATA</b></summary>

 SCORECARD DATA
 
 - df_debt_earn_panel_labelled, field_ay=='2017-18' refers to "FieldOfStudyData1617_1718"
 - terms scorecard uses to refer to year/time period
   - Acad yr	Academic Year; differs by institution, but generally the period from September to June (e.g., AcadYr 2013-14 = 9/1/2013 - 5/31/2014)
   - AY	Award Year (e.g. AY 2013-14 = 7/1/2013-6/30/2014)
   - CY	Calendar Year (e.g. CY 2014 = 1/1/14-12/31/14)
   - DCY	IPEDS Data Collection Year (e.g., DCY2013-14 = the 2013-14 IPEDS collection)
- variables
  - ipedscount1 = Number of awards to all students in year 1 of the pooled debt cohort
    - for scorecard "FieldOfStudyData1617_1718" data, this refers to degrees granted in AY 2016-17 reported in IPEDS DCY2017-18
  - ipedscount2 = number of awards to all students in year 2 of the pooled debt cohort
    - for scorecard "FieldOfStudyData1617_1718" data, this refers to degrees granted in AY 2017-18 reported in IPEDS DCY2018-19
- assumptions about relationship between MA degree awards and when students started MA program
  - Most (full-time) MA programs take one or two academic years to complete
  - Assuming two years for MA degree completion:
    - students awarded MA degrees in AY 2016-17 (e.g., May 2017) initially enrolled in Fall 2015 of 2015-16 academic year (year 1 = 2015-16; year 2 = 2016-17)
      - first paid tuition in fall 2015
    - students awarded MA degrees in AY 2017-18 (e.g., May 2018) initially enrolled in Fall 2016 of 2016-17 academic year (year 1 = 2016-17; year 2 = 2017-18)
      - first paid tuition in fall 2016

IPEDS DATA

- if you are matching IPEDS tuition price to ipedscount1 of "FieldOfStudyData1617_1718" data
  - choose tuition price from fall 2015 of 2015-16 academic year
    - file ic2015 provides tuition price for 2015-16 academic year
    - in df_ipeds_panel data frame, this is associated with year==2015
- if you are matching IPEDS tuition price to ipedscount2  of "FieldOfStudyData1617_1718" data
  - choose tuition price from fall 2016 of 2016-17 academic year
    - file ic2016 provides tuition price for 2016-17 academic year
    - in df_ipeds_panel data frame, this is associated with year==2016

DECISION

- assume we are matching IPEDS tuition price to ipedscount2  of "FieldOfStudyData1617_1718" data
- therefore: filter(year==2016)

</details> 


```{r}
# uncomment below line to remove all objects
  rm(list = ls())

# Libraries
  #install.packages('tidyverse') # if you haven't installed already
  #install.packages('labelled') # if you haven't installed already
  #install.packages('patchwork') # if you haven't installed already

library(tidyverse) # load tidyverse package
library(labelled) # load labelled package package
library(patchwork)

##########
########## TENNESSEE STAR DATA
##########

# load star data
load(file = url('https://github.com/anyone-can-cook/educ152/raw/main/data/star/star_panel_data.RData'))

#df_star_panel %>% glimpse()

# create data frame for STAR experiment, keeping only kindergarten
df_stark <- df_star_panel %>% 
  # keep only kindergarten year
  filter(grade ==1) %>% 
  # keep only observations with non-missing value for reading score
  filter(!is.na(read)) %>%
  # keep only observations with non-missing values for treatment assignment
  filter(!is.na(star)) %>%
  # drop observations where treatment status is regular+aide
  filter(star !=3) %>%
  # keep selected variables
  select(id,grade,star,read,gender,ethnicity,lunch,school,degree,experience) %>%
  # create a variable "treatment" that equals 1 if student receives treatment (small class) and equals 0 otherwise
  mutate(
    treatment = if_else(star==2,1,0)
  )

df_stark %>% glimpse()

rm(df_star_panel) # comment this line out if you want to keep data frame df_star_panel

##########
########## IPEDS
##########

# Load ipeds dataset from course website url
load(file = url('https://github.com/anyone-can-cook/educ152/raw/main/data/ipeds/output_data/panel_data.RData'))

# Create ipeds data frame with fewer variables/observations
df_ipeds_pop <- panel_data %>%
  # keep IPEDS tuition data from fall of which year (e.g., fall 2016 is price for programs in 2016-17 academic year)
  filter(year == 2016) %>%
  # which universities to keep:
    # 2015 carnegie classification: keep research universities (15,16,17) and master's universities (18,19,20)
  filter(c15basic %in% c(15,16,17,18,19,20)) %>%
  # which variables to keep
  select(instnm,unitid,opeid6,opeid,control,c15basic,stabbr,city,zip,locale,obereg, # basic institutional characteristics
         tuition6,fee6,tuition7,fee7, # avg tuition and fees for full-time grad, in-state and out-of-state
         isprof3,ispfee3,osprof3,ospfee3, # avg tuition and fees for MD, in-state and out-of-state
         isprof9,ispfee9,osprof9,ospfee9, # avg tuition and fees for Law, in-state and out-of-state
         chg4ay3,chg7ay3,chg8ay3) %>% # [undergraduate] books+supplies; off-campus (not with family) room and board; off-campus (not with family) other expenses
  # rename variables; syntax <new_name> = <old_name>
  rename(region = obereg, # revion
         tuit_grad_res = tuition6, fee_grad_res = fee6, tuit_grad_nres = tuition7, fee_grad_nres = fee7, # grad
         tuit_md_res = isprof3, fee_md_res = ispfee3, tuit_md_nres = osprof3, fee_md_nres = ospfee3, # md
         tuit_law_res = isprof9, fee_law_res = ispfee9, tuit_law_nres = osprof9, fee_law_nres = ospfee9, # law
         books_supplies = chg4ay3, roomboard_off = chg7ay3, oth_expense_off = chg8ay3) %>% # [undergraduate] expenses
  # create measures of tuition+fees
  mutate(
    tuitfee_grad_res = tuit_grad_res + fee_grad_res, # graduate, state resident
    tuitfee_grad_nres = tuit_grad_nres + fee_grad_nres, # graduate, non-resident
    tuitfee_md_res = tuit_md_res + fee_md_res, # MD, state resident
    tuitfee_md_nres = tuit_md_nres + fee_md_nres, # MD, non-resident
    tuitfee_law_res = tuit_law_res + fee_law_res, # Law, state resident
    tuitfee_law_nres = tuit_law_nres + fee_law_nres) %>% # Law, non-resident  
  # create measures of cost-of-attendance (COA) as the sum of tuition, fees, book, living expenses
  mutate(
    coa_grad_res = tuit_grad_res + fee_grad_res + books_supplies + roomboard_off + oth_expense_off, # graduate, state resident
    coa_grad_nres = tuit_grad_nres + fee_grad_nres + books_supplies + roomboard_off + oth_expense_off, # graduate, non-resident
    coa_md_res = tuit_md_res + fee_md_res + books_supplies + roomboard_off + oth_expense_off, # MD, state resident
    coa_md_nres = tuit_md_nres + fee_md_nres + books_supplies + roomboard_off + oth_expense_off, # MD, non-resident
    coa_law_res = tuit_law_res + fee_law_res + books_supplies + roomboard_off + oth_expense_off, # Law, state resident
    coa_law_nres = tuit_law_nres + fee_law_nres + books_supplies + roomboard_off + oth_expense_off) # %>% # Law, non-resident    
  # [COMMENTED THIS OUT] keep only observations that have non-missing values for the variable coa_grad_res
    # this does cause us to lose some interesting universities, but doing this will eliminate some needless complications with respect to learning core concepts about statistical inference
  #filter(!is.na(coa_grad_res))

# Add variable labels to the tuit+fees variables and coa variables
  # tuition + fees variables
    var_label(df_ipeds_pop[['tuitfee_grad_res']]) <- 'graduate, full-time, resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_grad_nres']]) <- 'graduate, full-time, non-resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_md_res']]) <- 'MD, full-time, state resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_md_nres']]) <- 'MD, full-time, non-resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_law_res']]) <- 'Law, full-time, state resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_law_nres']]) <- 'Law, full-time, non-resident; avg tuition + required fees'
    
  # COA variables
    var_label(df_ipeds_pop[['coa_grad_res']]) <- 'graduate, full-time, state resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_grad_nres']]) <- 'graduate, full-time, non-resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_md_res']]) <- 'MD, full-time, state resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_md_nres']]) <- 'MD, full-time, non-resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_law_res']]) <- 'Law, full-time, state resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_law_nres']]) <- 'Law, full-time, non-resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'

df_ipeds_pop %>% glimpse()

rm(panel_data) # comment this line out if you want to keep data frame panel_data

##########
########## SCORECARD DATA ON DEBT AND EARNINGS
##########

# load scorecard dataset from course website url

load(file = url('https://github.com/anyone-can-cook/educ152/raw/main/data/college_scorecard/output_data/df_debt_earn_panel_labelled.RData'))

df_scorecard <- df_debt_earn_panel_labelled %>%
    # keep most recent year of data
    filter(field_ay == '2017-18') %>%
    # keep master's degrees
    filter(credlev == 5) %>%
    # carnegie categories to keep: 15 = Doctoral Universities: Very High Research Activity; 16 = Doctoral Universities: High Research Activity
      # note: variable ccbasic from scorecard data is 2015 carnegie classification
    filter(ccbasic %in% c(15,16,17,18,19,20)) %>%
    # drop "parent plus" loan variables and other vars we won't use in this lecture
    select(-contains('_pp'),-contains('_any'),-field_ay,-st_fips,-zip,-longitude,-latitude,-locale2,-highdeg,-accredagency,-relaffil,-hbcu,-annhi,-tribal,-aanapii,-hsi,-nanti,-main,-numbranch,-control) %>%
    # create variable for broad field of degree (e.g., education, business)
    mutate(cipdig2 = str_sub(string = cipcode, start = 1, end = 2)) %>%
    # shorten variable cipdesc to make it more suitable for printing
    mutate(cipdesc = str_sub(string = cipdesc, start = 1, end = 50)) %>%
    # re-order variables
    relocate(opeid6,unitid,instnm,ccbasic,stabbr,city,cipdig2)

# "glimpse" data frame
df_scorecard %>% glimpse()

# For debt and earnings variables, convert from character to numeric variables (which replaces "PrivacySuppressed" values with NA values)
df_scorecard <- df_scorecard %>%
  mutate(
    debt_all_stgp_eval_n = as.numeric(debt_all_stgp_eval_n),
    debt_all_stgp_eval_mean = as.numeric(debt_all_stgp_eval_mean),
    debt_all_stgp_eval_mdn = as.numeric(debt_all_stgp_eval_mdn),
    debt_all_stgp_eval_mdn10yrpay = as.numeric(debt_all_stgp_eval_mdn10yrpay),
    earn_count_wne_hi_1yr = as.numeric(earn_count_wne_hi_1yr),
    earn_mdn_hi_1yr = as.numeric(earn_mdn_hi_1yr),
    earn_count_wne_hi_2yr = as.numeric(earn_count_wne_hi_2yr),
    earn_mdn_hi_2yr = as.numeric(earn_mdn_hi_2yr)
  ) 

# add variable label to variable cipdig2
  attr(df_scorecard[['cipdig2']], which = 'label') <- 'broad degree field code = 2-digit classification of instructional programs (CIP) degree code'

# add variable label attribute back to debt and earnings variables
  for(v in c('debt_all_stgp_eval_n','debt_all_stgp_eval_mean','debt_all_stgp_eval_mdn','debt_all_stgp_eval_mdn10yrpay','earn_count_wne_hi_1yr','earn_mdn_hi_1yr','earn_count_wne_hi_2yr','earn_mdn_hi_2yr','cipdesc')) {
    
    #writeLines(str_c('object v=', v))
    #writeLines(attr(df_debt_earn_panel_labelled[[v]], which = 'label'))
    
    attr(df_scorecard[[v]], which = 'label') <- attr(df_debt_earn_panel_labelled[[v]], which = 'label')
  }

df_scorecard %>% glimpse()

rm(df_debt_earn_panel_labelled) # comment this line out if you want to keep data frame df_debt_earn_panel_labelled
#earn_mdn_hi_2yr
##########
########## LEFT JOIN SCORECARD AND IPEDS DATA
##########

df_scorecard %>% glimpse()

# investigate data structure

  # df_scorecard; these vars uniquely identify observations
    df_scorecard %>% group_by(opeid6,cipcode) %>% summarise(n_per_key=n()) %>% ungroup() %>% count(n_per_key)

  # df_ipeds_pop: these vars uniquely identify observations
    df_ipeds_pop %>% group_by(unitid) %>% summarise(n_per_key=n()) %>% ungroup() %>% count(n_per_key)
    
# join
  # start with df_ipeds_pop, keep selected variables; then do do a right_join (i.e., keep obs in y table)
    
  df_score_ipeds <- df_ipeds_pop %>% 
    select(-instnm,-opeid6,-opeid,-c15basic,-region,-locale,-city,-stabbr,-zip) %>% mutate(one=1) %>%
    right_join(y=df_scorecard, by = 'unitid')
     #df_score_ipeds %>% glimpse()
  
  # 52 unitids from scorecard that don't have a match in ipeds
    # could be due to differences in year; decision: drop thiese
    df_score_ipeds %>% filter(is.na(one)) %>% count(unitid) # 52 unitids from scorecard data with missing IPEDS data
    df_score_ipeds %>% filter(is.na(one)) %>% count(instnm) # 52 unitids from scorecard data with missing IPEDS data
  
    
    
  df_score_ipeds <- df_score_ipeds %>% 
    # drop unitids from scorecard that don't merge to ipeds data (on tuition)
    filter(!is.na(one)) %>% 
    # drop observations that don't have mean debt data
    filter(!is.na(debt_all_stgp_eval_mean)) %>% 
    # drop for-profits
    filter(control !=3) %>%
    # drop tuition/coa vars for law and md
    select(-one,-contains('law'),-contains('md_')) %>%
    relocate(opeid6,unitid,instnm,control,ccbasic,stabbr,region,city,locale,cipdig2,cipcode,cipdesc,credlev,creddesc,
      contains('ipeds'),starts_with('debt'),starts_with('earn'))
    
  df_score_ipeds %>% glimpse()

rm(df_ipeds_pop) # comment this line out if you want to keep ipeds data frame
rm(df_scorecard) # comment this line out if you want to keep scorecard data frame

# Investigate analysis data frame `df_score_ipeds`  
  df_score_ipeds %>% glimpse()
  
  # data structure: variables that uniquely identify obs
    df_score_ipeds %>% group_by(opeid6,cipcode) %>% summarise(n_per_key=n()) %>% ungroup() %>% count(n_per_key)
  
  # number of observations (universities) for each 4-digit cip code (degree code)
    #df_score_ipeds %>% count(cipcode)
    df_score_ipeds %>% filter(cipcode=='4407') %>% count(cipcode) # social work
  
# create data frame that only contains observations for MAs in social work; filter(cipcode=='4407')
  df_socialwork <- df_score_ipeds %>% filter(cipcode=='4407')
  
  # one observation per opeid6
  df_socialwork %>% group_by(opeid6) %>% summarise(n_per_key=n()) %>% ungroup() %>% count(n_per_key)
  
  # also, one observation per unitid
  df_socialwork %>% group_by(unitid) %>% summarise(n_per_key=n()) %>% ungroup() %>% count(n_per_key)
  
```






```{r}

##########
########## RUN SCRIPT THAT CREATES USER DEFINED FUNCTIONS
##########

source(file = url('https://github.com/anyone-can-cook/educ152/raw/main/scripts/user_defined_functions/create_inference_functions.R'))
```


# Review: scatterplot, covariance, correlation

__Relationships between two continuous variables__

Postive relationship, negative relationship, and no relationships

<br>

1. Relationship between X and Y is positive
- when X is "high", Y tend to be "high"
- when X is "low", Y tends to be "low"
- e.g., number of hours (X) studying and GPA (Y)
- e.g., cost of attendance (X) and student debt (Y)

<br>

2. Relationship between X and Y is negative
- when X is "high", Y tend to be "low"
- when X is "low", Y tends to be "high"
- e.g., number of school absences and GPA

<br>

3. No relationship between X and Y
- knowing the value of X gives you does not tell you much about the value of Y
- e.g., amount of ice cream consumed and GPA


__Today's Example__

we will use the data frame `df_socialwork` (which combines debt/earnings data from College Scorecard and tuition/cost of attendance data from IPEDS) to run regression models of the relationship between measures of tuition/COA (X variable) and debt/earnings (Y variable) for MA programs in social work

- Potential X variables:
  - `tuitfee_grad_res`
  - `tuitfee_grad_nres`
  - `coa_grad_res`
  - `coa_grad_nres`
  - *Note*. for private institutions there is no difference between resident and nonresident price
- Potential Y variable
  - `debt_all_stgp_eval_mean`
    - this is average debt at the university for students graduates from that particular program (e.g., MA in social work)
    - think of it as "typical debt" (because confusing to think that a variable is a mean)
  - `debt_all_stgp_eval_mdn10yrpay`
    - typical (median) monthly payment on debt (assuming 10 year payment plan)
  - `earn_mdn_hi_2yr`
    - typical (median) earnings two years after graduation
```{r}
  df_socialwork %>% glimpse()

  # mean variable values
  df_socialwork %>% 
    summarize(
      n = n(),
      coa_grad_res_n = sum(!is.na(coa_grad_res)),
      coa_grad_res_mean = mean(coa_grad_res, na.rm = TRUE),
      debt_n = sum(!is.na(debt_all_stgp_eval_mean)),
      debt_mean = mean(debt_all_stgp_eval_mean, na.rm = TRUE),
      debt_mth_mean = mean(debt_all_stgp_eval_mdn10yrpay, na.rm = TRUE),
      earn_2yr_n = sum(!is.na(earn_mdn_hi_2yr)),
      earn_2yr_mean = mean(earn_mdn_hi_2yr, na.rm = TRUE)
      
    )
  
  # mean variable values by control (public/private)
  df_socialwork %>% group_by(control) %>%
    summarize(
      n = n(),
      coa_grad_res_n = sum(!is.na(coa_grad_res)),
      coa_grad_res_mean = mean(coa_grad_res, na.rm = TRUE),
      debt_n = sum(!is.na(debt_all_stgp_eval_mean)),
      debt_mean = mean(debt_all_stgp_eval_mean, na.rm = TRUE),
      debt_mth_mean = mean(debt_all_stgp_eval_mdn10yrpay, na.rm = TRUE),
      earn_2yr_n = sum(!is.na(earn_mdn_hi_2yr)),
      earn_2yr_mean = mean(earn_mdn_hi_2yr, na.rm = TRUE)
    )
```


<br>

For now, let's work with these two variables (X and Y)

- X (independent variable) = `coa_grad_res` = full-time graduate resident cost of attendance
- Y (dependent variable) = `debt_all_stgp_eval_mean` = typical (mean) debt from Direct Loans/GradPlus

<br>

Ways to investigate this relationship between X and Y:

- Graphically: scatterplots
- Numerically: covariance (less used), correlation


## Scatterplots

Scatterplots will plot individual observations on an X and Y axis

<br>

Draw scatterplot of X (`coa_grad_res`) and Y (`debt_all_stgp_eval_mean`)
```{r}
df_socialwork %>%  ggplot(aes(x=coa_grad_res, y=debt_all_stgp_eval_mean)) + geom_point()
```

<br>

Create scatterplot with "prediction" line
```{r}
df_socialwork %>%  ggplot(aes(x=coa_grad_res, y=debt_all_stgp_eval_mean)) + geom_point() + stat_smooth(method = 'lm')
```


- Residual
  - Difference between actual observed value of Y and predicted value of Y (given X)
  - predicted value of Y for a given value of X is represented by the "prediction line" above



## Covariance

Covariance measures the extent to which two variables move together....

- If debt is "high" when cost of attendance is "high", then covariance is positive
  - ("high" means a value that is higher than the mean value for the variable)
- If debt is "low" when cost of attendance is "high", then covariance is negative
  - (low" means a value that is lower than the mean value for the variable)

<br>

Population covariance, denoted $cov(X, Y)$ or $\sigma_{XY}$

- As with all population parameters, we don't know this!

<br>

Sample covariance, $s_{XY}$ or $\hat{\sigma}_{XY}$

- Estimator of population covariance

- $s_{XY}= \hat{\sigma}_{XY}=\frac{\sum_{i=1}^{n}\left(X_{i}-\bar{X} \right)  \left( Y_{i}-\bar{Y} \right)}{n-1}$



<br>

Example: Imagine we have 20 obs; $\bar{X}=40; \bar{Y}=30$

<br>

Observation 1: $X_1=50; Y_1=60$

- $(X_{i}-\bar{X})( Y_{i}-\bar{Y})=(50-40)(60-30)=10*30=300$
- $X_i >  \bar{X}$ and $Y_i > \bar{Y}$; so $(X_{i}-\bar{X})( Y_{i}-\bar{Y})$ is positive


Observation 2: $X_1=45; Y_1=25$

- $(X_{i}-\bar{X})( Y_{i}-\bar{Y})=(45-40)(25-30)=5*-5=-25$
- $X_i >  \bar{X}$ and $Y_i < \bar{Y}$; so $(X_{i}-\bar{X})( Y_{i}-\bar{Y})$ is positive


<br>

$\hat{\sigma}_{XY}=s_{XY}$ is the sum of these 20 calculations divided by 19 (n-1)


$\hat{\sigma}_{XY}=s_{XY}$ is positive when X and Y move in the same direction

- $X_i >  \bar{X}$ usually coupled with $Y_i > \bar{Y}$
- $X_i <  \bar{X}$ usually coupled with $Y_i < \bar{Y}$

<br>

$\hat{\sigma}_{XY}=s_{XY}$ is negative when X and Y move in the same direction

- $X_i >  \bar{X}$ usually coupled with $Y_i < \bar{Y}$
- $X_i <  \bar{X}$ usually coupled with $Y_i > \bar{Y}$


```{r}
cov(df_socialwork$coa_grad_res, df_socialwork$debt_all_stgp_eval_mean, use = 'complete.obs') # positive covariance
```


## Correlation

Problem with sample covariance, $s_{XY}$

- The value of covariance dependes on the units of measurement of the underlying variable
- We can't compare the covaraince of X and Y vs covariance of X and Z

which covariance is larger?

- covariance between cost of attendance and debt? or covariance between between cost of attendance and earnings
- not clear!
```{r}
cov(df_socialwork$coa_grad_res, df_socialwork$debt_all_stgp_eval_mean, use = 'complete.obs')
cov(df_socialwork$coa_grad_res, df_socialwork$earn_mdn_hi_2yr, use = 'complete.obs')
```

<br>

Sample Correlation of Z and Y, $r_{XY}$

- Unitless measure of relationship between X and Y
- Equals sample covariance, $s_{XY}$, divided by the product of their individual sample standard deviations

<br>

__Sample Correlation Formula__
$r_{XY}=\frac{s_{XY}}{s_X*s_Y}  = \frac{\hat{\sigma}_{XY}}{\hat{\sigma}_X \hat{\sigma}_Y}$


__Sample Correlation__

$r_{XY}=\frac{s_{XY}}{s_X*s_Y}  = \frac{\hat{\sigma}_{XY}}{\hat{\sigma}_X \hat{\sigma}_Y}$

<br>

Correlations result in measures between -1 and 1

<br>

"Type" of relationship

- $r_{XY}$ = 0 means there is no relationship between X and Y
- $r_{XY}$ > 0 means a positive correlation between X and Y
  - in other words, the variables move together
- $r_{XY}$ < 0 means a negative correlation
  - in other words, the variables move in opposite directions
  
<br>

"Strength" of relationship

- $r_{XY}$ = |0.1| to |0.3| = weak relationship
- $r_{XY}$ = |0.3| to |0.6| = moderate relationship
- $r_{XY}$ = |0.6| to |1| = strong relationship

<br>

Calculate correlations in R...

- correlation between cost of attendance and debt is stronger than correlation between cost of attendance and earnings
```{r}
cor(df_socialwork$coa_grad_res, df_socialwork$debt_all_stgp_eval_mean, use = 'complete.obs')
cor(df_socialwork$coa_grad_res, df_socialwork$earn_mdn_hi_2yr, use = 'complete.obs')
```


## Linear vs Non-Linear Relationships

Problem with covariance and correlation:

- Both measure linear relationships, defined as relationships between two variables that are captured by a straight line;
- These measures do not detect non-linear relationships, defined as relationships between two variables that are not captured by a straight line

<br>

Below, scatterplot of relationship between cost of attendance (X) and debt (Y) with a linear prediction line fitted

- this is the relationship captureD by covariance and correlation
```{r}
df_socialwork %>%  ggplot(aes(x=coa_grad_res, y=debt_all_stgp_eval_mean)) + geom_point() + stat_smooth(method = 'lm', formula = y ~ x + I(x^2), size = 1)
```
Scatterplot of relationship between cost of attendance (X) and debt (Y) with a prediction line that includes X1= cost of attendance and X2 = cost of attendance squared
```{r}
df_socialwork %>%  ggplot(aes(x=coa_grad_res, y=earn_mdn_hi_2yr)) + geom_point() + stat_smooth(method = 'lm', formula = y ~ x + I(x^2), size = 1)
```




# Population linear regression model

## Purpose of Regression

- Regression analysis is a statistical method that helps us analyze and understand the relationship between 2+ variables
- What is the purpose of regression in __descriptive research__ (sometimes called "observational studies" or "predictive" studies)?

  - To understand __relationship(s)__ between one dependent variable (Y) to one or more indepedent variable (X, Z, etc.)
  - Not concerned with "direction" or "cause": Does X cause Y? Does Y cause X? 
  - Interested in "prediction"
  - Example: predict poverty status based on having a cell phone

<br>

- What is the purpose of regression in __econometrics research__ (sometimes called "causal studies")?

  - To estimate the __causal__ effect of an independent variable (X) on a dependent variable (Y)
  - Very concerned with "direction" or "cause": Does X cause Y?  
  - Interested in recreating experimental conditions or what would have happened under a randomized control trial 
  - Example: What is the effect of class size on student learning?

<br>

- Most of my research is descriptive; but I teach this class in a "causal" way... why?
  - One type of research is not better than the other; it's just really important to understand the difference. _Ex: Lack of a cell phone doesnâ€™t cause poverty!_
  - Causal research forces you to be very purposeful about your models!
  - Policy makers/decision makers don't just care if there is a relationship between class size and student learning; they want to know if we decrease class size by two students what is the causal effect on student achievement


__Regression: Models, Variables, Relationships__

- __Linear Regression Model vs Non-Linear Regression Models__
  - Linear regression model (general linear model)
    - the dependent variable is continuous
    - e.g., GPA, test scores, income
    - __the focus of this class!__
  - Non-linear regression models (logit, ordinal, probit, poisson, negative binomial)
    - the dependent variable is non-continuous (i.e., categorical, binary, counts)
    - e.g., persistence, likert scales, type of major

<br>
    

- __Bivariate vs Multivariate Regression__
  - Bivariate regression (sometimes also called univariate, simple regression)
    - One dependent variable (Y) and one independent variable of interest ($X_1$)
  - Multivariate regression (for econometrics/causal inference)

    - One dependent variable (Y) and one independent variable of interest ($X_1$); __and__ multiple control variables ($X_2$,$X_3$,$X_4$,etc.)
    
<br>

- __Linear Relationship vs Non-Linear Relationship between X and Y__
  - Draw linear vs non-linear relationship scatterplots; show in R
  - We will focus on modeling linear relationship between X and Y for first half of the course
  - Then we will cover non-linear relationships
  


__Slope Measures relationship between X and Y__

- Research Question
  - What is the effect of cost of attendance (X) on student debt (Y)
  
<br>

- What do we want to measure?
  - The relationship between cost of attendance (X) and student debt (Y)
  - If we increase the number of cost of attendance per week by $1,000, how much do we expect student debt to change?

<br>

- We want to measure $\beta$
  - $\beta = \frac{(Y_2 - Y_1)}{(X_2 - X_1)} = \frac{\Delta Y}{\Delta X}$
  - In other words, the slope of the relationship between X and Y 
  - Under the assumption of a linear relationship
  
<br>

- Draw line showing linear relationship between X and Y
  - $x_1 = 31, x_2 =32, y_1=\$30,000, Y_2=\$35,000$
  - Calculate slope at different points and for different $\Delta X$

## Population Linear Regression Model

__Population__ Linear Regression Model

- $Y_i = \beta_0 + \beta_1X_i + u_i$

<br>

Where:

- $Y_i$ = typical student debt at university i
- $X_i$ = cost of attendance at university i
- $\beta_0$ ("population intercept") = average debt at a university with X=0 (cost of attendance = 0)
- $\beta_1$ ("population regression coefficient") = average effect of a one-unit increase in X on the value of Y
- $u_1$ ("error term" or "residual") = all other variables not included in your model that affect the value of Y

<br>

Draw Picture

- Scatterplot of the population
- Population regression model line
- Label the following:
  - $\beta_0$
  - $\beta_1$
  - residual (predicted - value of $Y_i$)

## Population Regression Model

__Population__ Linear Regression Model
$Y_i = \beta_0 + \beta_1X_i + u_i$

<br>

Contains two population parameters

- $\beta_0$ ("population intercept") = average student debt for someone with X=0 
- $\beta_1$ ("population regression coefficient") = average effect of a one-unit increase in X on the value of Y

<br>

- How do we know these are population parameters? (hint: notation)
- Do we usually know the value of $\beta_0$ or $\beta_1$? 

### Population regression coefficient, $\beta_1$

What is the effect of cost of attendance (X) on student debt (Y)?

- Answer: population regression coefficient, $\beta_1$
- Estimating $\beta_1$ is the fundamental goal of causal inference/this course 

<br>

What is the population regression coefficient, $\beta_1$?

- $\beta_1$ measures the average change in Y for a one-unit increase in X

- Think of $\beta_1$ as measuring the slope of our prediction line!

- $\beta_1 = \frac{\Delta Y}{\Delta X} = \frac{\Delta student\_debt}{\Delta cost\_of\_attendance}$

- Example: $\beta_1$ = $\frac{\$5000 \Delta student\_debt}{\$1000 \Delta cost\_of\_attendance}$ = $xxxx

<br>

Interpretation (we will use this all semester!)

- General interpretation:
  - On average, a one unit-increase in X is associated with a $\beta_1$ increase (or decrease) in the value of Y
- Interpretation from example above:
  - On average, a one-hour increase in cost of attendance (X) is associated with a \$xxx ($\beta_1$) increase in student debt (Y)
- Interpret if $\beta_1 = \$2,000$; or $\beta_1 = \$4,000$


Some important things to remember:

- If $\beta_1$ (i.e., the relationship between X and Y) is linear, then the average change in Y for a one-unit increase in X is the same no matter the starting value of X
  - Like plot example from earlier

- $\beta_1$ measures the **average** effect on Y for a one-unit increase in X; this effect on an individual observation may be different than this average effect! 

- $\beta_1$  is a population parameter. We hardly ever know population parameters. So we **estimate** $\beta_1$  using sample data!

### Population Intercept, $\beta_0$

What is the effect of cost of attendance (X) on student debt (Y)?

  - $Y_i = \beta_0 + \beta_1X_i + u_i$

<br>

$\beta_0$ is the "population intercept"

- $\beta_0$ = the average value of Y when X=0
- Here, $\beta_0$, is the average student debt for university where cost of attendance equals $0 (X=0)
- Usually, we are not substantively interested in $\beta_0$ 
- Sometimes $\beta_0$ is non-sensical or there's too few observations at X=0 to calculate a precise estimate (e.g., effect of cost of attendance on student debt cuz grad school is never free)


### Population Linear Regression Line

__Population__ Linear Regression Model
$Y_i = \beta_0 + \beta_1X_i + u_i$

<br> 

We sometimes deconstruct the Population Linear Regression Model into two parts:

(1) __Population__ Linear Regression *LINE*/ Regression Function: $Y_i = \beta_0 + \beta_1X_i$
(2) __Population__ "Error" or "Residual" Term: $u_i$

<br> 

- Population regression line: just a linear prediction line, like the one in the scatterplot *if* the scatterplot contained all observation in the population
- Population regression line measures the "average" or "expected" relationship between X and Y, ignoring variables that we excluded from the model (i.e., $u_i$)

Population regression line and Expected Value, E(Y)

- Expected value of Y (for a sample mean/ one variable)
  - $E(Y) = \mu_Y$
  
<br>

- Expected value of Y, given the value of X (relationship between two variables)
  - $E(Y|X) = \beta_0 + \beta_1X_i$
  - the population regression line is expected value of Y for a given value of X

<br>
  
- Population regression line and prediction
  - If we know value of parameters, $\beta_0$ and $\beta_1$, we can predict value of Y
  - Example: $\beta_0=\$5,000$ and $\beta_1=\$2,000$
  - (1) Predict the value of Y (student debt) for university where cost of attendance is $20K
  - (2) Predict the value of Y (student debt) for university where cost of attendance is $40K
  
  
### $u_i$, as "Error Term" or "unobserved variables"

- Population linear regression model
  - $Y_i = \beta_0 + \beta_1X_i + u_i$
  - Y= student debt; $X_i$= cost of attendance

<br>

- In causal inference research:
  - Error term $u_i$ represents (consists of) *all other variables besides X that are not included in your model* that affect the dependent variable
  - In other words, the error term consists of all other factors (i.e., variables) responsible for the difference between the $i^{th}$ district's average test score and the value predicted by the regression line
  - This interpretation will become *super* important down the road!
  
<br>

- Example of Y= student debt; $X_i$= cost of attendance; the error term $u_i$ would consist of other factors besides cost of attendance that have an effect on student debt
  - cost of healthcare; whether students can rely on parents to pay for graduate school; how much grant aid students are awarded
  

<br> 

- In other social science based statistics classes
  - Interpret the $u_i$ as the overall error in the prediction of Y due to *random variation*


### $u_i$ as "Residual"

- Population linear regression model
  - $Y_i = \beta_0 + \beta_1X_i + u_i$
  - Y= student debt; $X_i$= cost of attendance
  
<br> 

- $u_i$ as the residual
  - Population regression line represents the predicted value of Y (student debt) for each value of X (cost of attendance)
  - Residual = the predicted value of Y - observed value of Y for any given value of X

<br>

- Easier to conceptually think about $u_i$ in terms of each observation, i

  - $Y_i$ = actual value of student debt for person i
  - $Y_i = \beta_0 + \beta_1X_i$ = Population Regression line 
    -  The predicted value of student debt for university i with cost of attendance = $X_i$
  - Residual, $u_i$
    - The difference between actual value, $Y_i$, and predicted value from the population regression line for observation i
    - $u_i = Y_i - (\beta_0 + \beta_1X_i)$
    

# Estimation


__General things we do in regression analysis__

1. __Estimation__ [Today]
  - How do we choose estimates of $\beta_0$ and $\beta_1$ using sample data?

<br>

2. __Prediction__ [Next Week]
  - What is the predicted value of Y for someone with a particular value of X?
  
<br>
  
3. __Hypothesis testing__ [focus of the rest of the semester]
  - Hypothesis testing and confidence intervals about $\beta_1$
  

<br>

Step 1 of regression is to estimate parameters

Population linear regression model

  - $Y_i = \beta_0 + \beta_1X_i + u_i$

<br>

__Goal of estimation is to__:

  - Use sample data to estimate the population intercept, $\beta_0$, and the population regression coefficient, $\beta_1$
  - $\hat{\beta_0}$ is an estimate of $\beta_0$
  - $\hat{\beta_1}$ is an estimate of $\beta_1$
    - How dow we know these estimates are based on sample data and not population parameters? (hint: notation!)
    
<br>

__Estimation problem__:

Need to develop a method for choosing values of $\hat{\beta_0}$ and $\hat{\beta_1}$ 


## Estimation (population mean)

We faced a similar estimation problem in intro to stats!

- Use sample to calculate the "best" estimate of the population mean, $\mu_Y$
- We decided sample mean, $\bar{Y}$, was the "best" estimate!

<br>

Criteria we used to determine $\bar{Y}$ was "best" estimate of $\mu_Y$

- $m$ is all potential estimates for $\mu_Y$
- Goal: choose the value, $m$ , that minimizes the "sum of squares"
  - Sum of squares = $\sum_{i=1}^{n}$ $(Y_i-m)^2$
  - $\bar{Y}$ is the value of $m$ that minimizes sum of squares
  - So $\bar{Y}$ is the "least squares" estimator 
  
<br>

Draw scatterplot:

- (1) Horizontal line representing sample mean
  - Show formula for sum of square errors
  
## Estimation (regression)


Problem in regression:

- Need to develop method for selecting the "best" estimate of $\hat{\beta_0}$ and $\hat{\beta_1}$
- Solution: similar to what we do for population mean!

<br>

First some terminology:

- $Y_i$ is the actual observed value of Y for individual i
- $\hat{Y_i}$ is the predicted value of $Y_i$, based on sample data!
  - $\hat{Y_i} = \hat{\beta_0} + \hat{\beta_1}X_i$
  
- Estimated residual, $\hat{u}_i$ is the difference between actual $Y_i$ and predicted $\hat{Y_i}$
  - $Y_i - \hat{Y_i}$ = $\hat{u_i}$
  - $Y_i - (\hat{\beta_0} + \hat{\beta_1}X_i)$ = $\hat{u_i}$
  - Residuals are sometimes called "errors"
  

Criteria for choosing "best" estimate of $\hat{\beta_0}$ and $\hat{\beta_1}$

- Select values that minimize "sum of squared residuals"

<br>

Sum of squared residuals (or sometimes called "sum of squared errors"):

- $\sum_{i=1}^{n}$ $(Y_i - \hat{Y_i})^2$

- $\sum_{i=1}^{n}$ $(Y_i - (\hat{\beta_0} + \hat{\beta_1}X_i))^2$

- $\sum_{i=1}^{n}$ $(u_i)^2$


<br>

__Ordinary Least Squares__ is a linear method for estimating parameters in a linear regression model

  - Method draws a line through the sample data points that minimizes the sum of squared residuals, or in other words, the differences between the observed values and the corresponding fitted values
  - Minimization is achieved via calculus (derivatives). R will calculate this for you (phew!)
  - Best estimates of  $\hat{\beta_0}$ and $\hat{\beta_1}$ are those that any other alternatives would result in a higher sum of squared residuals
  

### OLS Prediction Line

__Population Linear Regression Model__

 - $Y_i = \beta_0 + \beta_1X_i + u_i$
 
<br>

__OLS Prediction Line or "OLS Regression Line" (based on sample data)__

 - $\hat{Y_i} = \hat{\beta_0} + \hat{\beta_1}X_i$ 
 
<br>

- Our OLS prediction line chose the best estimates of  $\hat{\beta_0}$ and $\hat{\beta_1}$ as  those that any other alternatives would result in a higher sum of squared residuals
- Draw this out...


## Regression in R using `lm()`

Let's write run our first regression and write out our models!

<br>
  
RQ: What is the effect of cost of attendance on student debt? 

- Run regression in R
  - `mod1 <- lm(realrinc ~ hrs1, data=gss)`
  - `summary(mod1)`

![](output.png)


RQ: What is the effect of cost of attendance on student debt? 

<br>
Write out and label everything within the following: [we will be doing this all semester!]

1. Population regression model
    - Label Y; Label X

2. OLS Prediction Line (without estimates)
    - Define $\hat{\beta_0}$?
    - Define $\hat{\beta_1}$?

3. OLS Prediction Line (with estimates)
    - Interpret $\hat{\beta_0}$ given the estimate 
    - Interpret $\hat{\beta_1}$ given the estimate 

4. Predict the expected value of $\hat{Y}_i$ for xxxxxx




## In-Class Group Exercise 

RQ: What is the effect of age on XXXX?? 

- hint! X = `age` and Y =`realrinc`

<br>

Write out and label everything within the following

- Recommendation: Practice how to write out equations in Word; touch-screen devices share your screen via whiteboard


1. Population regression model
    - Label Y; Label X

2. OLS Prediction Line (without estimates)
    - Define $\hat{\beta_0}$?
    - Define $\hat{\beta_1}$?

3. OLS Prediction Line (with estimates)
    - Run regression in R and print to get estimates: 
      - `mod2 <-  lm(realrinc ~ age, data=gss)`
      - `summary(mod2)`
    - Interpret $\hat{\beta_0}$ given the estimate 
    - Interpret $\hat{\beta_1}$ given the estimate 

4. Predict the expected value of $\hat{Y}_i$ for someone that is 18 years old.



__In-Class Group Exercise [Solutions]__

RQ: What is the effect of age on annual income??  [CHANGE THIS]


1. Population regression model
    - $Y_i = \beta_0 + \beta_1X_i + u_i$
    - Y = annual income; X = age

2. OLS Prediction Line (without estimates)
    - $\hat{Y_i} = \hat{\beta_0} + \hat{\beta_1}X_i$
    - $\hat{\beta_0}$? = Sample population intercept
      - i.e., the average value of Y when X=0
    - $\hat{\beta_1}$ = Sample regression coefficient 
      - i.e., the average change in Y for one-unit increase in X

3. OLS Prediction Line (with estimates)
    - $\hat{Y_i} = \$8,620 + \$368X_i$
    - $\hat{\beta_0}$ = \$8,620
      - On average, someone who is age zero has an annual income of \$8,620 
      - Example of non-sensical $\hat{\beta_0}$
    - $\hat{\beta_1}$? = \$368
      - On average, a one-year increase in age is associated with a \$368 increase in annual income

4. Predict the expected value of $\hat{Y}_i$ for someone that is 18 years old.
    - $E(\hat{Y_i}|X=35)$ = $\hat{Y_i} = \$8,620 + \$368*18$
    - $E(\hat{Y_i}|X=35)$ = $\hat{Y_i} = \$8,620 + \$6,624$
    - $E(\hat{Y_i}|X=35)$ = \$15,244





# Prediction

ADD TEXT

# Model Fit

ADD TEXT



# References